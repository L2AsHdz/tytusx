/* parser generated by jison 0.4.18 */
/*
  Returns a Parser object of the following structure:

  Parser: {
    yy: {}
  }

  Parser.prototype: {
    yy: {},
    trace: function(),
    symbols_: {associative list: name ==> number},
    terminals_: {associative list: number ==> name},
    productions_: [...],
    performAction: function anonymous(yytext, yyleng, yylineno, yy, yystate, $$, _$),
    table: [...],
    defaultActions: {...},
    parseError: function(str, hash),
    parse: function(input),

    lexer: {
        EOF: 1,
        parseError: function(str, hash),
        setInput: function(input),
        input: function(),
        unput: function(str),
        more: function(),
        less: function(n),
        pastInput: function(),
        upcomingInput: function(),
        showPosition: function(),
        test_match: function(regex_match_array, rule_index),
        next: function(),
        lex: function(),
        begin: function(condition),
        popState: function(),
        _currentRules: function(),
        topState: function(),
        pushState: function(condition),

        options: {
            ranges: boolean           (optional: true ==> token location info will include a .range[] member)
            flex: boolean             (optional: true ==> flex-like lexing behaviour where the rules are tested exhaustively to find the longest match)
            backtrack_lexer: boolean  (optional: true ==> lexer regexes are tested in order and for each matching regex the action code is invoked; the lexer terminates the scan when a token is returned by the action code)
        },

        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START),
        rules: [...],
        conditions: {associative list: name ==> set},
    }
  }


  token location info (@$, _$, etc.): {
    first_line: n,
    last_line: n,
    first_column: n,
    last_column: n,
    range: [start_number, end_number]       (where the numbers are indexes into the input string, regular zero-based)
  }


  the parseError function receives a 'hash' object with these members for lexer and parser errors: {
    text:        (matched text)
    token:       (the produced terminal token, if any)
    line:        (yylineno)
  }
  while parser (grammar) errors will also provide these members, i.e. parser errors deliver a superset of attributes: {
    loc:         (yylloc)
    expected:    (string describing the set of expected tokens)
    recoverable: (boolean: TRUE when the parser has a error recovery rule available for this particular error)
  }
*/
var AnalyzerXMLDescendente = (function(){
var o=function(k,v,o,l){for(o=o||{},l=k.length;l--;o[k[l]]=v);return o},$V0=[1,14],$V1=[2,5,25],$V2=[1,22],$V3=[2,5,9,25],$V4=[1,26],$V5=[1,27],$V6=[1,28],$V7=[1,25],$V8=[1,32],$V9=[1,35],$Va=[1,38],$Vb=[8,11,12,13,15,26,28],$Vc=[2,17],$Vd=[1,49],$Ve=[1,50],$Vf=[8,26],$Vg=[1,65],$Vh=[1,66],$Vi=[1,67],$Vj=[10,12];
var parser = {trace: function trace() { },
yy: {},
symbols_: {"error":2,"START":3,"XML_STRUCTURE":4,"EOF":5,"PROLOG":6,"NODES":7,"greater_than":8,"less_than":9,"question_mark":10,"xml":11,"version":12,"assign":13,"value":14,"encoding":15,"TYPE_ENCODING":16,"OPCION_TEXTO_ETIQUETA":17,"NODE":18,"OPENING_TAG":19,"CLOSING_TAG":20,"EMPTY_TAG":21,"textTag":22,"IDENTIFIER":23,"ATTRIBS":24,"cierreEtiqueta":25,"slash":26,"ATTRIB":27,"identifier":28,"utf":29,"iso":30,"ascii":31,"$accept":0,"$end":1},
terminals_: {2:"error",5:"EOF",8:"greater_than",9:"less_than",10:"question_mark",11:"xml",12:"version",13:"assign",14:"value",15:"encoding",22:"textTag",25:"cierreEtiqueta",26:"slash",28:"identifier",29:"utf",30:"iso",31:"ascii"},
productions_: [0,[3,2],[3,1],[3,2],[4,2],[4,3],[6,12],[6,12],[6,3],[7,2],[7,1],[18,3],[18,2],[18,1],[18,3],[18,4],[17,1],[17,0],[19,4],[19,5],[20,4],[20,2],[21,5],[21,6],[24,2],[24,1],[27,3],[23,1],[23,1],[23,1],[23,1],[16,1],[16,1],[16,1]],
performAction: function anonymous(yytext, yyleng, yylineno, yy, yystate /* action[1] */, $$ /* vstack */, _$ /* lstack */) {
/* this == yyval */

var $0 = $$.length - 1;
switch (yystate) {
case 1:

        let auxRetorno = new NodoPadre(getId(),"START","-> START","",
                [
                    new NodoPadre(getId(),"XML_STRUCTURE","START -> XML_STRUCTURE EOF","return XML_STRUCTURE.info",$$[$0-1].hijos),
                    new NodoHijo(getId(),"EOF","","")
                ]
            );            
        return {nodos:$$[$0-1].nodos,raizCST:auxRetorno};
        
break;
case 2:
        
        return {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,raizCST:new NodoPadre(getId(),"XML_STRUCTURE","EOF","",[])
            };
    
break;
case 3:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        return {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,raizCST:new NodoPadre(getId(),"START","error EOF","",[])
            };
    
break;
case 4:

        nodos = [];
        this.$ = {nodos:$$[$0].nodos
        ,hijos:[
                new NodoPadre(getId(),"PROLOG","XML_STRUCTURE -> PROLOG NODES","XML_STRUCTURE.info = [PROLOG.valor,NODES.listado]",$$[$0-1].hijos),
                new NodoPadre(getId(),"NODES","","",$$[$0].hijos)
            ]
        };
        
break;
case 5:

        nodos = [];
        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,hijos:[new NodoPadre(getId(),"XML_STRUCTURE","error sintactico","",[])]
            };
    
break;
case 6:

        this.$ = {hijos:[
            new NodoHijo(getId(),"<","PROLOG -> &lt;?xml version = value encoding = TYPE_ENCODING ?&gt;","PROLOG.encoding = TYPE_ENCODING.valor"),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),"xml","",""),
            new NodoHijo(getId(),"version","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoHijo(getId(),"value","",""),
            new NodoHijo(getId(),"encoding","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoPadre(getId(),"TYPE_ENCODING","","",$$[$0-3].hijos),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),">","",""),
            new NodoPadre(getId(),"OPCION_TEXTO_ETIQUETA","","",$$[$0].hijos),
        ]};
    
break;
case 7:

        this.$ = {hijos:[
            new NodoHijo(getId(),"<","PROLOG -> &lt;?xml version = value encoding = TYPE_ENCODING ?&gt;","PROLOG.encoding = TYPE_ENCODING.valor"),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),"xml","",""),
            new NodoHijo(getId(),"encoding","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoPadre(getId(),"TYPE_ENCODING","","",$$[$0-6].hijos),
            new NodoHijo(getId(),"version","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoHijo(getId(),"value","",""),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),">","",""),
            new NodoPadre(getId(),"OPCION_TEXTO_ETIQUETA","","",$$[$0].hijos),
        ]};
    
break;
case 8:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,hijos:[new NodoPadre(getId(),"PROLOG","error sintactico","",[])]
            };
    
break;
case 9:

        nodos.unshift($$[$0-1].nodo);
        this.$ = {nodos:nodos
        ,hijos:[
                new NodoPadre(getId(),"NODE","NODES -> NODE NODES","NODES1.agregar(NODE.valor)<br>NODES.listado = NODES1.listado",$$[$0-1].hijos),
                new NodoPadre(getId(),"NODES","","",$$[$0].hijos)
            ]
        };
        
break;
case 10:

        nodos.push($$[$0].nodo);
        this.$ = {nodos:nodos
            ,hijos:[
                new NodoPadre(getId(),"NODE","NODES -> NODE","NODES.valor = nuevoListado[NODE.valor]",$$[$0].hijos)
            ]
        };
        
break;
case 11:

        nodos = [];
        if($$[$0-2].identificador === $$[$0].identificador){
            this.$ = {nodo:new Nodo($$[$0-2].identificador, $$[$0-2].atributos, $$[$0-1].nodos, Type.DOUBLE_TAG,  $$[$0-2].textoEtiqueta, _$[$0-2].first_line, (_$[$0-2].first_column + 1))
            ,hijos:[
                    new NodoPadre(getId(),"OPENING_TAG","NODE -> OPENING_TAG NODES CLOSING_TAG","NODE.valor = nuevoNodo(NODES.listado)",$$[$0-2].hijos),
                    new NodoPadre(getId(),"NODES","","",$$[$0-1].hijos),
                    new NodoPadre(getId(),"CLOSING_TAG","","",$$[$0].hijos)
                ]
            };
        }else{
            errores.agregarError("Semantico","El id de etiqueta no coincide:<br>&lt;"+$$[$0-2].identificador+"&gt;&lt;/"+$$[$0].identificador+"&gt;",this._$.first_line,(this._$.first_column+1));
            this.$ = {nodo:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
                ,hijos:[new NodoPadre(getId(),"NODE","error semantico","",[])]
                };
        }
        
        
break;
case 12:

        if($$[$0-1].identificador === $$[$0].identificador){
            this.$ = {nodo:new Nodo($$[$0-1].identificador, $$[$0-1].atributos, [], Type.DOUBLE_TAG,  $$[$0-1].textoEtiqueta, _$[$0-1].first_line, (_$[$0-1].first_column + 1))
            ,hijos:[
                    new NodoPadre(getId(),"OPENING_TAG","NODE -> OPENING_TAG CLOSING_TAG","NODE.valor = nuevoNodo()",$$[$0-1].hijos),
                    new NodoPadre(getId(),"CLOSING_TAG","","",$$[$0].hijos)
                ]
            };
        }else{
            errores.agregarError("Semantico","El id de etiqueta no coincide:<br>&lt;"+$$[$0-1].identificador+"&gt;&lt;/"+$$[$0].identificador+"&gt;",this._$.first_line,(this._$.first_column+1));
            this.$ = {nodo:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
                ,hijos:[new NodoPadre(getId(),"NODE","error sematico","",[])]
                };
        }
        
break;
case 13:

        this.$ = {nodo:new Nodo($$[$0].identificador, $$[$0].atributos, [], Type.EMPTY,       $$[$0].textoEtiqueta, _$[$0].first_line, (_$[$0].first_column + 1))
        ,hijos:[
                new NodoPadre(getId(),"EMPTY_TAG","NODE -> EMPTY_TAG","NODE.valor = nuevoNodo()",$$[$0].hijos)
            ]
        };
        
break;
case 14: case 15:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodo:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
            ,hijos:[new NodoPadre(getId(),"NODE","error sintactico","",[])]
            };
    
break;
case 16:

        this.$ = {contenido: $$[$0],
                hijos:[
                    new NodoPadre(getId(),$$[$0],"OPCION_TEXTO_ETIQUETA -> textTag","OPCION_TEXTO_ETIQUETA.valor = textTag.valorLexico",[])
                ]
            };
        
break;
case 17:

        this.$ = {contenido:"",hijos:[new NodoHijo(getId(),"lambda","OPCION_TEXTO_ETIQUETA -> lambda ","")]};
        
break;
case 18:

        this.$={identificador:$$[$0-2].contenido
            ,textoEtiqueta:$$[$0].contenido
            ,atributos:[]
            ,hijos:[
                new NodoHijo(getId(),"<","OPENING_TAG -> < IDENTIFIER > ","OPENING_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-2].hijos),
                new NodoHijo(getId(),">","",""),
                new NodoPadre(getId(),"OPCION_TEXTO_ETIQUETA","","",$$[$0].hijos)
            ]
        };

        
break;
case 19:
        
        atributos = [];
        this.$={identificador:$$[$0-3].contenido
            ,textoEtiqueta:$$[$0].contenido
            ,atributos:$$[$0-2].atributos
            ,hijos:[
                new NodoHijo(getId(),"<","OPENING_TAG -> < IDENTIFIER ATRIBS > OPCION_TEXTO_ETIQUETA","OPENING_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-3].hijos),
                new NodoPadre(getId(),"ATRIBS","","",$$[$0-2].hijos),
                new NodoHijo(getId(),">","",""),
                new NodoPadre(getId(),"OPCION_TEXTO_ETIQUETA","","",$$[$0].hijos)
            ]
        };
        
break;
case 20:

        this.$ = {identificador:$$[$0-2].contenido
                ,hijos:[
                    new NodoHijo(getId(),"<","CLOSING_TAG -> < / IDENTIFIER > OPCION_TEXTO_ETIQUETA","CLOSING_TAG.valor = IDENTIFIER.valor"),
                    new NodoHijo(getId(),"/","",""),
                    new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-2].hijos),
                    new NodoHijo(getId(),">","","")
            ]
            };
        
break;
case 21:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodos:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
            ,hijos:[new NodoPadre(getId(),"CLOSING_TAG","error sintactico","",[])]
            };
    
break;
case 22:

            this.$={identificador:$$[$0-3].contenido
                ,textoEtiqueta: $$[$0].contenido
                ,atributos:[]
                ,hijos:[
                    new NodoHijo(getId(),"<","EMPTY_TAG -> < IDENTIFIER / > OPCION_TEXTO_ETIQUETA","EMPTY_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                    new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-3].hijos),
                    new NodoHijo(getId(),"/","",""),
                    new NodoHijo(getId(),">","",""),
                    new NodoPadre(getId(),"OPCION_TEXTO_ETIQUETA","","",$$[$0].hijos)
                ]
            };

            
break;
case 23:

        atributos = [];
        this.$={identificador:$$[$0-4].contenido
            ,textoEtiqueta: $$[$0].contenido
            ,atributos: $$[$0-3].atributos
            ,hijos:[
                    new NodoHijo(getId(),"<","EMPTY_TAG -> < IDENTIFIER ATRIBS / > OPCION_TEXTO_ETIQUETA","EMPTY_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                    new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-4].hijos),
                    new NodoPadre(getId(),"ATRIBS","","",$$[$0-3].hijos),
                    new NodoHijo(getId(),"/","",""),
                    new NodoHijo(getId(),">","",""),
                    new NodoPadre(getId(),"OPCION_TEXTO_ETIQUETA","","",$$[$0].hijos)
                ]
        };
        
break;
case 24:

            atributos.unshift($$[$0-1].atributo);
            this.$ = {atributos:atributos
                ,hijos:[
                    new NodoPadre(getId(),"ATRIB","ATRIBS -> ATRIB ATRIBS","ATRIB1.agregar(ATRIB.valor)<br>ATRIBS.listado = ATRIB1.listado",$$[$0-1].hijos),
                    new NodoPadre(getId(),"ATRIBS","","",$$[$0].hijos)
                ]
            };
            
break;
case 25:

        atributos.push($$[$0].atributo);
            this.$ = {atributos:atributos, hijos:[ new NodoPadre(getId(),"ATRIB","ATRIBS -> ATRIB","ATRIBS.valor = nuevoListado[ATRIB.valor]",$$[$0].hijos) ] };
        
break;
case 26:

        this.$ = {atributo:
            new Atributo($$[$0-2].contenido,$$[$0].replaceAll('\"', ""), Type.ATRIBUTO, _$[$0-2].first_line, (_$[$0-2].first_column + 1))
            ,hijos:[
                new NodoPadre(getId(),"IDENTIFIER","ATRIB -> IDENTIFIER = value","ATRIB.valor=value.lexicoValor",$$[$0-2].hijos),
                new NodoHijo(getId(),"=","",""),
                new NodoHijo(getId(),"value","","")
            ]
        }
        ;
break;
case 27:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> identifier","IDENTIFIER.valor = identifier.lexicoValor")]};
break;
case 28:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> xml"       ,"IDENTIFIER.valor = xml.lexicoValor")]};
break;
case 29:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> version"   ,"IDENTIFIER.valor = version.lexicoValor")]};
break;
case 30:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> encoding"  ,"IDENTIFIER.valor = encoding.lexicoValor")]};
break;
case 31:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"TYPE_ENCODING -> "+$$[$0],"TYPE_ENCODING.valor = uft.lexicoValor")]};
break;
case 32:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"TYPE_ENCODING -> "+$$[$0],"TYPE_ENCODING.valor = iso.lexicoValor")]};
break;
case 33:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"TYPE_ENCODING -> "+$$[$0],"TYPE_ENCODING.valor = ascii.lexicoValor")]};
break;
}
},
table: [{2:[1,4],3:1,4:2,5:[1,3],6:5,9:[1,6]},{1:[3]},{5:[1,7]},{1:[2,2]},{5:[1,8],8:[1,9]},{7:10,9:$V0,18:11,19:12,21:13},{2:[1,16],10:[1,15]},{1:[2,1]},{1:[2,3]},{7:17,9:$V0,18:11,19:12,21:13},{5:[2,4]},o($V1,[2,10],{18:11,19:12,21:13,7:18,9:$V0}),{2:[1,21],7:19,9:$V0,18:11,19:12,20:20,21:13,25:$V2},o($V3,[2,13]),{2:[1,23],11:$V4,12:$V5,15:$V6,23:24,28:$V7},{11:[1,29]},{8:[1,30]},{5:[2,5]},o($V1,[2,9]),{2:$V8,20:31,25:$V2},o($V3,[2,12]),{2:$V8,9:$V9,19:34,20:33,25:$V2},{11:$V4,12:$V5,15:$V6,23:36,28:$V7},{8:[1,37]},{8:$Va,11:$V4,12:$V5,15:$V6,23:42,24:39,26:[1,40],27:41,28:$V7},o($Vb,[2,27]),o($Vb,[2,28]),o($Vb,[2,29]),o($Vb,[2,30]),{12:[1,43],15:[1,44]},{9:[2,8]},o($V3,[2,11]),{9:$V9,19:34},{5:[1,45]},o($V3,[2,21]),{11:$V4,12:$V5,15:$V6,23:46,28:$V7},{8:[1,47]},o($V3,[2,14]),o($V3,$Vc,{17:48,22:$Vd}),{8:$Ve,26:[1,51]},{8:[1,52]},o($Vf,[2,25],{27:41,23:42,24:53,11:$V4,12:$V5,15:$V6,28:$V7}),{13:[1,54]},{13:[1,55]},{13:[1,56]},o($V3,[2,15]),{8:$Va,11:$V4,12:$V5,15:$V6,23:42,24:57,27:41,28:$V7},o($V3,$Vc,{17:58,22:$Vd}),o($V3,[2,18]),o($V3,[2,16]),o($V3,$Vc,{17:59,22:$Vd}),{8:[1,60]},o($V3,$Vc,{17:61,22:$Vd}),o($Vf,[2,24]),{14:[1,62]},{14:[1,63]},{16:64,29:$Vg,30:$Vh,31:$Vi},{8:$Ve},o($V3,[2,20]),o($V3,[2,19]),o($V3,$Vc,{17:68,22:$Vd}),o($V3,[2,22]),o([8,11,12,15,26,28],[2,26]),{15:[1,69]},{12:[1,70]},o($Vj,[2,31]),o($Vj,[2,32]),o($Vj,[2,33]),o($V3,[2,23]),{13:[1,71]},{13:[1,72]},{16:73,29:$Vg,30:$Vh,31:$Vi},{14:[1,74]},{10:[1,75]},{10:[1,76]},{8:[1,77]},{8:[1,78]},{9:$Vc,17:79,22:$Vd},{9:$Vc,17:80,22:$Vd},{9:[2,6]},{9:[2,7]}],
defaultActions: {3:[2,2],7:[2,1],8:[2,3],10:[2,4],17:[2,5],30:[2,8],79:[2,6],80:[2,7]},
parseError: function parseError(str, hash) {
    if (hash.recoverable) {
        this.trace(str);
    } else {
        var error = new Error(str);
        error.hash = hash;
        throw error;
    }
},
parse: function parse(input) {
    var self = this,
        stack = [0],
        tstack = [], // token stack
        vstack = [null], // semantic value stack
        lstack = [], // location stack
        table = this.table,
        yytext = '',
        yylineno = 0,
        yyleng = 0,
        recovering = 0,
        TERROR = 2,
        EOF = 1;

    var args = lstack.slice.call(arguments, 1);

    //this.reductionCount = this.shiftCount = 0;

    var lexer = Object.create(this.lexer);
    var sharedState = { yy: {} };
    // copy state
    for (var k in this.yy) {
      if (Object.prototype.hasOwnProperty.call(this.yy, k)) {
        sharedState.yy[k] = this.yy[k];
      }
    }

    lexer.setInput(input, sharedState.yy);
    sharedState.yy.lexer = lexer;
    sharedState.yy.parser = this;
    if (typeof lexer.yylloc == 'undefined') {
        lexer.yylloc = {};
    }
    var yyloc = lexer.yylloc;
    lstack.push(yyloc);

    var ranges = lexer.options && lexer.options.ranges;

    if (typeof sharedState.yy.parseError === 'function') {
        this.parseError = sharedState.yy.parseError;
    } else {
        this.parseError = Object.getPrototypeOf(this).parseError;
    }

    function popStack (n) {
        stack.length = stack.length - 2 * n;
        vstack.length = vstack.length - n;
        lstack.length = lstack.length - n;
    }

_token_stack:
    var lex = function () {
        var token;
        token = lexer.lex() || EOF;
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }
        return token;
    }

    var symbol, preErrorSymbol, state, action, a, r, yyval = {}, p, len, newState, expected;
    while (true) {
        // retreive state number from top of stack
        state = stack[stack.length - 1];

        // use default actions if available
        if (this.defaultActions[state]) {
            action = this.defaultActions[state];
        } else {
            if (symbol === null || typeof symbol == 'undefined') {
                symbol = lex();
            }
            // read action for current state and first input
            action = table[state] && table[state][symbol];
        }

_handle_error:
        // handle parse error
        if (typeof action === 'undefined' || !action.length || !action[0]) {
            var error_rule_depth;
            var errStr = '';

            // Return the rule stack depth where the nearest error rule can be found.
            // Return FALSE when no error recovery rule was found.
            function locateNearestErrorRecoveryRule(state) {
                var stack_probe = stack.length - 1;
                var depth = 0;

                // try to recover from error
                for(;;) {
                    // check for error recovery rule in this state
                    if ((TERROR.toString()) in table[state]) {
                        return depth;
                    }
                    if (state === 0 || stack_probe < 2) {
                        return false; // No suitable error recovery rule available.
                    }
                    stack_probe -= 2; // popStack(1): [symbol, action]
                    state = stack[stack_probe];
                    ++depth;
                }
            }

            if (!recovering) {
                // first see if there's any chance at hitting an error recovery rule:
                error_rule_depth = locateNearestErrorRecoveryRule(state);

                // Report error
                expected = [];
                for (p in table[state]) {
                    if (this.terminals_[p] && p > TERROR) {
                        expected.push("'"+this.terminals_[p]+"'");
                    }
                }
                if (lexer.showPosition) {
                    errStr = 'Parse error on line '+(yylineno+1)+":\n"+lexer.showPosition()+"\nExpecting "+expected.join(', ') + ", got '" + (this.terminals_[symbol] || symbol)+ "'";
                } else {
                    errStr = 'Parse error on line '+(yylineno+1)+": Unexpected " +
                                  (symbol == EOF ? "end of input" :
                                              ("'"+(this.terminals_[symbol] || symbol)+"'"));
                }
                this.parseError(errStr, {
                    text: lexer.match,
                    token: this.terminals_[symbol] || symbol,
                    line: lexer.yylineno,
                    loc: yyloc,
                    expected: expected,
                    recoverable: (error_rule_depth !== false)
                });
            } else if (preErrorSymbol !== EOF) {
                error_rule_depth = locateNearestErrorRecoveryRule(state);
            }

            // just recovered from another error
            if (recovering == 3) {
                if (symbol === EOF || preErrorSymbol === EOF) {
                    throw new Error(errStr || 'Parsing halted while starting to recover from another error.');
                }

                // discard current lookahead and grab another
                yyleng = lexer.yyleng;
                yytext = lexer.yytext;
                yylineno = lexer.yylineno;
                yyloc = lexer.yylloc;
                symbol = lex();
            }

            // try to recover from error
            if (error_rule_depth === false) {
                throw new Error(errStr || 'Parsing halted. No suitable error recovery rule available.');
            }
            popStack(error_rule_depth);

            preErrorSymbol = (symbol == TERROR ? null : symbol); // save the lookahead token
            symbol = TERROR;         // insert generic error symbol as new lookahead
            state = stack[stack.length-1];
            action = table[state] && table[state][TERROR];
            recovering = 3; // allow 3 real symbols to be shifted before reporting a new error
        }

        // this shouldn't happen, unless resolve defaults are off
        if (action[0] instanceof Array && action.length > 1) {
            throw new Error('Parse Error: multiple actions possible at state: '+state+', token: '+symbol);
        }

        switch (action[0]) {
            case 1: // shift
                //this.shiftCount++;

                stack.push(symbol);
                vstack.push(lexer.yytext);
                lstack.push(lexer.yylloc);
                stack.push(action[1]); // push state
                symbol = null;
                if (!preErrorSymbol) { // normal execution/no error
                    yyleng = lexer.yyleng;
                    yytext = lexer.yytext;
                    yylineno = lexer.yylineno;
                    yyloc = lexer.yylloc;
                    if (recovering > 0) {
                        recovering--;
                    }
                } else {
                    // error just occurred, resume old lookahead f/ before error
                    symbol = preErrorSymbol;
                    preErrorSymbol = null;
                }
                break;

            case 2:
                // reduce
                //this.reductionCount++;

                len = this.productions_[action[1]][1];

                // perform semantic action
                yyval.$ = vstack[vstack.length-len]; // default to $$ = $1
                // default location, uses first token for firsts, last for lasts
                yyval._$ = {
                    first_line: lstack[lstack.length-(len||1)].first_line,
                    last_line: lstack[lstack.length-1].last_line,
                    first_column: lstack[lstack.length-(len||1)].first_column,
                    last_column: lstack[lstack.length-1].last_column
                };
                if (ranges) {
                  yyval._$.range = [lstack[lstack.length-(len||1)].range[0], lstack[lstack.length-1].range[1]];
                }
                r = this.performAction.apply(yyval, [yytext, yyleng, yylineno, sharedState.yy, action[1], vstack, lstack].concat(args));

                if (typeof r !== 'undefined') {
                    return r;
                }

                // pop off stack
                if (len) {
                    stack = stack.slice(0,-1*len*2);
                    vstack = vstack.slice(0, -1*len);
                    lstack = lstack.slice(0, -1*len);
                }

                stack.push(this.productions_[action[1]][0]);    // push nonterminal (reduce)
                vstack.push(yyval.$);
                lstack.push(yyval._$);
                // goto new state = table[STATE][NONTERMINAL]
                newState = table[stack[stack.length-2]][stack[stack.length-1]];
                stack.push(newState);
                break;

            case 3:
                // accept
                return true;
        }

    }

    return true;
}};

    let idNodos = 0;
    function getId(){        
        return idNodos++;
    }
    let atributos = [];
    let nodos = [];
/* generated by jison-lex 0.3.4 */
var lexer = (function(){
var lexer = ({

EOF:1,

parseError:function parseError(str, hash) {
        if (this.yy.parser) {
            this.yy.parser.parseError(str, hash);
        } else {
            throw new Error(str);
        }
    },

// resets the lexer, sets new input
setInput:function (input, yy) {
        this.yy = yy || this.yy || {};
        this._input = input;
        this._more = this._backtrack = this.done = false;
        this.yylineno = this.yyleng = 0;
        this.yytext = this.matched = this.match = '';
        this.conditionStack = ['INITIAL'];
        this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0
        };
        if (this.options.ranges) {
            this.yylloc.range = [0,0];
        }
        this.offset = 0;
        return this;
    },

// consumes and returns one char from the input
input:function () {
        var ch = this._input[0];
        this.yytext += ch;
        this.yyleng++;
        this.offset++;
        this.match += ch;
        this.matched += ch;
        var lines = ch.match(/(?:\r\n?|\n).*/g);
        if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
        } else {
            this.yylloc.last_column++;
        }
        if (this.options.ranges) {
            this.yylloc.range[1]++;
        }

        this._input = this._input.slice(1);
        return ch;
    },

// unshifts one char (or a string) into the input
unput:function (ch) {
        var len = ch.length;
        var lines = ch.split(/(?:\r\n?|\n)/g);

        this._input = ch + this._input;
        this.yytext = this.yytext.substr(0, this.yytext.length - len);
        //this.yyleng -= len;
        this.offset -= len;
        var oldLines = this.match.split(/(?:\r\n?|\n)/g);
        this.match = this.match.substr(0, this.match.length - 1);
        this.matched = this.matched.substr(0, this.matched.length - 1);

        if (lines.length - 1) {
            this.yylineno -= lines.length - 1;
        }
        var r = this.yylloc.range;

        this.yylloc = {
            first_line: this.yylloc.first_line,
            last_line: this.yylineno + 1,
            first_column: this.yylloc.first_column,
            last_column: lines ?
                (lines.length === oldLines.length ? this.yylloc.first_column : 0)
                 + oldLines[oldLines.length - lines.length].length - lines[0].length :
              this.yylloc.first_column - len
        };

        if (this.options.ranges) {
            this.yylloc.range = [r[0], r[0] + this.yyleng - len];
        }
        this.yyleng = this.yytext.length;
        return this;
    },

// When called from action, caches matched text and appends it on next action
more:function () {
        this._more = true;
        return this;
    },

// When called from action, signals the lexer that this rule fails to match the input, so the next matching rule (regex) should be tested instead.
reject:function () {
        if (this.options.backtrack_lexer) {
            this._backtrack = true;
        } else {
            return this.parseError('Lexical error on line ' + (this.yylineno + 1) + '. You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).\n' + this.showPosition(), {
                text: "",
                token: null,
                line: this.yylineno
            });

        }
        return this;
    },

// retain first n characters of the match
less:function (n) {
        this.unput(this.match.slice(n));
    },

// displays already matched input, i.e. for error messages
pastInput:function () {
        var past = this.matched.substr(0, this.matched.length - this.match.length);
        return (past.length > 20 ? '...':'') + past.substr(-20).replace(/\n/g, "");
    },

// displays upcoming input, i.e. for error messages
upcomingInput:function () {
        var next = this.match;
        if (next.length < 20) {
            next += this._input.substr(0, 20-next.length);
        }
        return (next.substr(0,20) + (next.length > 20 ? '...' : '')).replace(/\n/g, "");
    },

// displays the character position where the lexing error occurred, i.e. for error messages
showPosition:function () {
        var pre = this.pastInput();
        var c = new Array(pre.length + 1).join("-");
        return pre + this.upcomingInput() + "\n" + c + "^";
    },

// test the lexed token: return FALSE when not a match, otherwise return token
test_match:function (match, indexed_rule) {
        var token,
            lines,
            backup;

        if (this.options.backtrack_lexer) {
            // save context
            backup = {
                yylineno: this.yylineno,
                yylloc: {
                    first_line: this.yylloc.first_line,
                    last_line: this.last_line,
                    first_column: this.yylloc.first_column,
                    last_column: this.yylloc.last_column
                },
                yytext: this.yytext,
                match: this.match,
                matches: this.matches,
                matched: this.matched,
                yyleng: this.yyleng,
                offset: this.offset,
                _more: this._more,
                _input: this._input,
                yy: this.yy,
                conditionStack: this.conditionStack.slice(0),
                done: this.done
            };
            if (this.options.ranges) {
                backup.yylloc.range = this.yylloc.range.slice(0);
            }
        }

        lines = match[0].match(/(?:\r\n?|\n).*/g);
        if (lines) {
            this.yylineno += lines.length;
        }
        this.yylloc = {
            first_line: this.yylloc.last_line,
            last_line: this.yylineno + 1,
            first_column: this.yylloc.last_column,
            last_column: lines ?
                         lines[lines.length - 1].length - lines[lines.length - 1].match(/\r?\n?/)[0].length :
                         this.yylloc.last_column + match[0].length
        };
        this.yytext += match[0];
        this.match += match[0];
        this.matches = match;
        this.yyleng = this.yytext.length;
        if (this.options.ranges) {
            this.yylloc.range = [this.offset, this.offset += this.yyleng];
        }
        this._more = false;
        this._backtrack = false;
        this._input = this._input.slice(match[0].length);
        this.matched += match[0];
        token = this.performAction.call(this, this.yy, this, indexed_rule, this.conditionStack[this.conditionStack.length - 1]);
        if (this.done && this._input) {
            this.done = false;
        }
        if (token) {
            return token;
        } else if (this._backtrack) {
            // recover context
            for (var k in backup) {
                this[k] = backup[k];
            }
            return false; // rule action called reject() implying the next rule should be tested instead.
        }
        return false;
    },

// return next match in input
next:function () {
        if (this.done) {
            return this.EOF;
        }
        if (!this._input) {
            this.done = true;
        }

        var token,
            match,
            tempMatch,
            index;
        if (!this._more) {
            this.yytext = '';
            this.match = '';
        }
        var rules = this._currentRules();
        for (var i = 0; i < rules.length; i++) {
            tempMatch = this._input.match(this.rules[rules[i]]);
            if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                match = tempMatch;
                index = i;
                if (this.options.backtrack_lexer) {
                    token = this.test_match(tempMatch, rules[i]);
                    if (token !== false) {
                        return token;
                    } else if (this._backtrack) {
                        match = false;
                        continue; // rule action called reject() implying a rule MISmatch.
                    } else {
                        // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                        return false;
                    }
                } else if (!this.options.flex) {
                    break;
                }
            }
        }
        if (match) {
            token = this.test_match(match, rules[index]);
            if (token !== false) {
                return token;
            }
            // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
            return false;
        }
        if (this._input === "") {
            return this.EOF;
        } else {
            return this.parseError('Lexical error on line ' + (this.yylineno + 1) + '. Unrecognized text.\n' + this.showPosition(), {
                text: "",
                token: null,
                line: this.yylineno
            });
        }
    },

// return next match that has a token
lex:function lex() {
        var r = this.next();
        if (r) {
            return r;
        } else {
            return this.lex();
        }
    },

// activates a new lexer condition state (pushes the new lexer condition state onto the condition stack)
begin:function begin(condition) {
        this.conditionStack.push(condition);
    },

// pop the previously active lexer condition state off the condition stack
popState:function popState() {
        var n = this.conditionStack.length - 1;
        if (n > 0) {
            return this.conditionStack.pop();
        } else {
            return this.conditionStack[0];
        }
    },

// produce the lexer rule set which is active for the currently active lexer condition state
_currentRules:function _currentRules() {
        if (this.conditionStack.length && this.conditionStack[this.conditionStack.length - 1]) {
            return this.conditions[this.conditionStack[this.conditionStack.length - 1]].rules;
        } else {
            return this.conditions["INITIAL"].rules;
        }
    },

// return the currently active lexer condition state; when an index argument is provided it produces the N-th previous condition state, if available
topState:function topState(n) {
        n = this.conditionStack.length - 1 - Math.abs(n || 0);
        if (n >= 0) {
            return this.conditionStack[n];
        } else {
            return "INITIAL";
        }
    },

// alias for begin(condition)
pushState:function pushState(condition) {
        this.begin(condition);
    },

// return the number of states currently on the stack
stateStackSize:function stateStackSize() {
        return this.conditionStack.length;
    },
options: {},
performAction: function anonymous(yy,yy_,$avoiding_name_collisions,YY_START) {
var YYSTATE=YY_START;
switch($avoiding_name_collisions) {
case 0:console.log("Comentario "+yy_.yytext);
break;
case 1:console.log("texto etiqueta "+yy_.yytext);return 22;
break;
case 2:return 25;
break;
case 3://Ignorar espacios
break;
case 4:return 8;
break;
case 5:return 9;
break;
case 6:return 10;
break;
case 7:return 13;
break;
case 8:return 26;
break;
case 9:return 11;
break;
case 10:return 12;
break;
case 11:return 15;
break;
case 12:return 29;
break;
case 13:return 31;
break;
case 14:return 30
break;
case 15:return 14;
break;
case 16:return 28;
break;
case 17: return 5; 
break;
case 18:
                                agregarErrorLexico("Lexico",yy_.yytext,yy_.yylloc.first_line,yy_.yylloc.first_column+1);
                                //console.log('     error lexico '+yy_.yytext);
                                
break;
}
},
rules: [/^(?:<!--.*-->)/,/^(?:([^"<>"]*)(?=(<\/([A-ZÑa-zñ][A-ZÑa-zñ0-9_-]*)>))\b)/,/^(?:<\/)/,/^(?:\s+)/,/^(?:>)/,/^(?:<)/,/^(?:\?)/,/^(?:=)/,/^(?:\/)/,/^(?:xml\b)/,/^(?:version\b)/,/^(?:encoding\b)/,/^(?:"UTF-8")/,/^(?:"ASCII")/,/^(?:"ISO-8859-1")/,/^(?:(["][^"\""]+["])|(['][^']+[']))/,/^(?:\w+)/,/^(?:$)/,/^(?:.)/],
conditions: {"INITIAL":{"rules":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],"inclusive":true}}
});
return lexer;
})();
parser.lexer = lexer;
function Parser () {
  this.yy = {};
}
Parser.prototype = parser;parser.Parser = Parser;
return new Parser;
})();


if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
exports.parser = AnalyzerXMLDescendente;
exports.Parser = AnalyzerXMLDescendente.Parser;
exports.parse = function () { return AnalyzerXMLDescendente.parse.apply(AnalyzerXMLDescendente, arguments); };
exports.main = function commonjsMain(args) {
    if (!args[1]) {
        console.log('Usage: '+args[0]+' FILE');
        process.exit(1);
    }
    var source = require('fs').readFileSync(require('path').normalize(args[1]), "utf8");
    return exports.parser.parse(source);
};
if (typeof module !== 'undefined' && require.main === module) {
  exports.main(process.argv.slice(1));
}
}